---
title: Introduction to Postgres indexes
date: "2025-08-19T10:00:00.000Z"
description: A developer's guide to truly understanding database indexes, and how to weild them
---

## Introduction

This post is part 1 of a 2-part series on database indexes. Part 1 is a practical, hands-on, applicable approach to indexes. We'll cover what B+ trees are, of course, but with a focus on deeply understanding, and internalizing how they store data on disk, and how your database uses them to speed up queries.

This will set us up nicely for part 2, where we'll explore some interesting, counterintuitive ways to press indexes into service to achieve great querying performance over large amounts of data.

Everything in these posts will use Postgres, but absolutely everything is directly applicable to other relational databases. All the queries I'll be running are against a simple books database which I scaffolded, and had Cursor populate with about 90 million records. DDL for the database, as well as the code to fill it are in [this repo](https://github.com/arackaf/postgres-indexing-post) if you'd like to follow along on your own: `sql/db_create.sql` has the DDL, and `npx tsx insert-data/fill-database.ts` will run the code to fill it.

We'll be looking at some B+ Tree visualizations as we go. Those were put together with a web app I had Cursor help me build. The repo for that is [here](https://github.com/arackaf/btree-visualizer).

## Setting some baselines

Just for fun, let's take a look at the first 10 rows in the books table. Don't look too close, again, this was all algorithmically generated by AI. The special characters at the beginning were my crude way forcing the (extremely repetative) titles to spread out.

![Our data](/postgres-indexing-1/img1-data.png)

That's the last time we'll be looking at actual data. From here forward, we'll look at queries, the execution plans they generate, then we'll talk about how indexes might, or might not be able to help. Rather than the psql terminal utility I'll be running everything through DataGrip, which is an IDE for databases. The output is identical, except with nicely numbered lines, which will make things easier to talk about as we go.

Let's get started. Let's see what the prior query looks like by putting `explain analyze` before it. This tells Postgres to execute the query, and return to use the execution plan it used, as well as its performance.

```sql
explain analyze
select * from books limit 10;
```

![Execution plan](/postgres-indexing-1/img2-ex-plan.png)

We asked for 10 rows. The database did a Sequential scan on our books table, but with a limit of 10 applied. Couldn't be simpler, and returned in less than half of one millisecond. This is hardly surprising (or interesting). Postgres essentially just reached in and grabbed the first ten rows it found.

Let's grab the first 10 books, but this time sorted alphabetically.

![Sorted](/postgres-indexing-1/img3-ex-plan-sorted.png)

Catastrophically, this took 20 _seconds_. With 90 million rows in this table, Postgres now has to (kind of) sort the entire table, in order to know what the first 10 books are. I say kind of, since it doesn't _really_ have to sort the _entire_ table, just scan the entire table and grab the 10 rows with the lowest title values. That's why we see two child workers getting spawned (in addition to the main worker running out query) to each scan about a third of the table, and each take the top 7; this is reflected in lines 3-9 of the execution plan.

Line 5 makes this especially clear

```
->  Sort  (cost=2839564.34..2934237.14 rows=37869122 width=112) (actual time=20080.358..20080.359 rows=7 loops=3)
```

Notice the loops=3, the the rows = 37 million. Each worker is scanning its share of the table, and keeping the top 7 it sees.

These 3 groups of 7 are then _gathered_ and _merged_ together in the Gather Merge on line 2

```
->  Gather Merge  (cost=2840564.36..11677309.78 rows=75738244 width=112) (actual time=20093.790..20096.619 rows=10 loops=1)
```

Rather than just slapping an index in, and magically watching the time drop down, let's take a quick detour and make sure we really understand _how_ indexes work. Failing to do this can result in frustration when your database winds up not picking the index you want it to, for reasons that a good understanding could make clear.

## Indexes
